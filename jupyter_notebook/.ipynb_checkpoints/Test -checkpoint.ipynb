{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\Code_Test\\\\Research\\\\Surveys-Missing-Data-Imputation--master\\\\data_K_Fold\\\\abalone\\\\train\\\\data_missing_40\\\\train_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   nan,    nan,    nan, ...,    nan,    nan,  3.   ],\n",
       "       [ 0.67 ,  0.51 ,  0.175, ...,  0.345, 10.   ,  3.   ],\n",
       "       [ 0.67 ,  0.5  ,  0.19 , ...,  0.415, 10.   ,  3.   ],\n",
       "       ...,\n",
       "       [   nan,  0.43 ,  0.15 , ...,  0.22 ,  8.   ,  1.   ],\n",
       "       [ 0.62 ,  0.485,    nan, ...,  0.352,  9.   ,  1.   ],\n",
       "       [   nan,    nan,    nan, ...,  0.34 ,    nan,  3.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.genfromtxt(train_path, delimiter=',')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\Code_Test\\\\Research\\\\Surveys-Missing-Data-Imputation--master\\\\data_K_Fold\\\\abalone\\\\test\\\\data_missing_40\\\\test_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    nan,  0.195 ,  0.09  , ...,  0.0355,     nan,  2.    ],\n",
       "       [    nan,     nan,     nan, ...,     nan,     nan,  3.    ],\n",
       "       [ 0.66  ,  0.53  ,     nan, ...,     nan,     nan,  1.    ],\n",
       "       ...,\n",
       "       [    nan,     nan,     nan, ...,     nan,     nan,  2.    ],\n",
       "       [    nan,     nan,     nan, ...,     nan,     nan,  3.    ],\n",
       "       [ 0.49  ,  0.39  ,  0.15  , ...,  0.17  , 21.    ,  3.    ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.genfromtxt(test_path, delimiter=',')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 3., ..., 1., 1., 3.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0    2.0\n",
       "1    3.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    2.0\n",
       "..   ...\n",
       "829  2.0\n",
       "830  3.0\n",
       "831  2.0\n",
       "832  3.0\n",
       "833  3.0\n",
       "\n",
       "[834 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "imp_mean = SimpleImputer( strategy='mean')\n",
    "imp_mean.fit(X_train[:,:7], X_train[:,-1])\n",
    "imputed_train_df = imp_mean.transform(X_test[:, :7])\n",
    "pd.DataFrame(X_test[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   nan,    nan,    nan, ...,    nan,    nan,  3.   ],\n",
       "       [ 0.67 ,  0.51 ,  0.175, ...,  0.345, 10.   ,  3.   ],\n",
       "       [ 0.67 ,  0.5  ,  0.19 , ...,  0.415, 10.   ,  3.   ],\n",
       "       ...,\n",
       "       [   nan,  0.43 ,  0.15 , ...,  0.22 ,  8.   ,  1.   ],\n",
       "       [ 0.62 ,  0.485,    nan, ...,  0.352,  9.   ,  1.   ],\n",
       "       [   nan,    nan,    nan, ...,  0.34 ,    nan,  3.   ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3595 ,  0.195  ,  0.09   , ...,  0.0355 ,  6.2    ,  2.     ],\n",
       "       [ 0.5225 ,  0.4085 ,  0.1425 , ...,  0.26035, 10.2    ,  3.     ],\n",
       "       [ 0.66   ,  0.53   ,  0.1525 , ...,  0.32605, 10.6    ,  1.     ],\n",
       "       ...,\n",
       "       [ 0.4055 ,  0.3715 ,  0.112  , ...,  0.1598 ,  7.9    ,  2.     ],\n",
       "       [ 0.5225 ,  0.4085 ,  0.1425 , ...,  0.26035, 10.2    ,  3.     ],\n",
       "       [ 0.49   ,  0.39   ,  0.15   , ...,  0.17   , 21.     ,  3.     ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=10)\n",
    "imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4465 ,  0.195  ,  0.09   , ...,  0.0355 ,  9.     ,  2.     ],\n",
       "       [ 0.5795 ,  0.4335 ,  0.153  , ...,  0.2421 , 10.8    ,  3.     ],\n",
       "       [ 0.66   ,  0.53   ,  0.1575 , ...,  0.35295, 11.5    ,  1.     ],\n",
       "       ...,\n",
       "       [ 0.457  ,  0.3405 ,  0.11   , ...,  0.102  ,  7.9    ,  2.     ],\n",
       "       [ 0.5795 ,  0.4335 ,  0.153  , ...,  0.2421 , 10.8    ,  3.     ],\n",
       "       [ 0.49   ,  0.39   ,  0.15   , ...,  0.17   , 21.     ,  3.     ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(X_train)\n",
    "imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNImputer(add_indicator=False, copy=True, metric='nan_euclidean',\n",
       "           missing_values=nan, n_neighbors=10, weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNNImputer(add_indicator=False, copy=True, metric='nan_euclidean',\n",
       "           missing_values=nan, n_neighbors=5, weights='uniform')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy = \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SimpleImputer_mean'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleImputer.__name__ +\"_\"+ imp.strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imp.strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-9f87d53f6891>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimp_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSimpleImputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: join() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "imp_name = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "flag = [1,1,1]\n",
    "for i,_ in flag:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_md_y = [0, 1, 2, 2, 2]\n",
    "predict_label = [0, 0, 2, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, f1_macro, _ = precision_recall_fscore_support(test_md_y, predict_label, average='macro')\n",
    "accuracy = accuracy_score(test_md_y, predict_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48888888888888893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneigh = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNeighborsClassifier'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneigh.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassifier'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,std,mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1.0481352526332528\n",
      "2.269672331458316\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('newfilePath.csv', \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in a:\n",
    "        print(row)\n",
    "        writer.writerow(str(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('test.csv', a, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71449961, 0.81447519, 0.4907141 , 0.67992064],\n",
       "       [0.81390847, 0.7127158 , 0.43256118, 0.42323631],\n",
       "       [0.35488431, 0.37801875, 0.56371913, 0.05130302],\n",
       "       [0.7561533 , 0.71813108, 0.31901966, 0.6528093 ],\n",
       "       [0.81438809, 0.71710077, 0.5404173 , 0.51221637],\n",
       "       [0.24547296, 0.81299418, 0.22808699, 0.87745947],\n",
       "       [0.6587409 , 0.82935171, 0.13483538, 0.11805721],\n",
       "       [0.87016717, 0.12488407, 0.69198822, 0.76193006],\n",
       "       [0.76682954, 0.06409884, 0.8306078 , 0.19675907],\n",
       "       [0.55839986, 0.71917676, 0.12444165, 0.6897089 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(10,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14758937, 0.80613471, 0.04356243, 0.77873385],\n",
       "       [0.80297753, 0.70425701, 0.82375147, 0.65660998],\n",
       "       [0.65909254, 0.30470893, 0.51499962, 0.31389572],\n",
       "       [0.42401596, 0.63437727, 0.31153405, 0.17580596],\n",
       "       [0.27487432, 0.37354614, 0.6487247 , 0.15836202],\n",
       "       [0.92498544, 0.46299832, 0.78782906, 0.43516988]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.rand(6,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21082405],\n",
       "       [0.67578081],\n",
       "       [0.72258117],\n",
       "       [0.44091732],\n",
       "       [0.93030267],\n",
       "       [0.87066839],\n",
       "       [0.93285181],\n",
       "       [0.38898987],\n",
       "       [0.09033245],\n",
       "       [0.84830885]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21082405, 0.67578081, 0.72258117, 0.44091732, 0.93030267,\n",
       "       0.87066839, 0.93285181, 0.38898987, 0.09033245, 0.84830885])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71449961, 0.81447519, 0.4907141 , 0.67992064],\n",
       "       [0.81390847, 0.7127158 , 0.43256118, 0.42323631],\n",
       "       [0.35488431, 0.37801875, 0.56371913, 0.05130302],\n",
       "       [0.7561533 , 0.71813108, 0.31901966, 0.6528093 ],\n",
       "       [0.81438809, 0.71710077, 0.5404173 , 0.51221637],\n",
       "       [0.24547296, 0.81299418, 0.22808699, 0.87745947],\n",
       "       [0.6587409 , 0.82935171, 0.13483538, 0.11805721],\n",
       "       [0.87016717, 0.12488407, 0.69198822, 0.76193006],\n",
       "       [0.76682954, 0.06409884, 0.8306078 , 0.19675907],\n",
       "       [0.55839986, 0.71917676, 0.12444165, 0.6897089 ],\n",
       "       [0.14758937, 0.80613471, 0.04356243, 0.77873385],\n",
       "       [0.80297753, 0.70425701, 0.82375147, 0.65660998],\n",
       "       [0.65909254, 0.30470893, 0.51499962, 0.31389572],\n",
       "       [0.42401596, 0.63437727, 0.31153405, 0.17580596],\n",
       "       [0.27487432, 0.37354614, 0.6487247 , 0.15836202],\n",
       "       [0.92498544, 0.46299832, 0.78782906, 0.43516988]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((a,b), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'DTree': pd.Series([1,2,3,4], index=['KNN', 'MICE', 'Mean', 'Constant']),\n",
    "    'KNN': pd.Series([5,8,3,4], index=['KNN', 'MICE', 'Mean', 'Constant'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DTree</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICE</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Constant</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DTree  KNN\n",
       "KNN           1    5\n",
       "MICE          2    8\n",
       "Mean          3    3\n",
       "Constant      4    4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "random.seed(42)\n",
    "X, y = np.random.rand(5,4), range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30496917, 0.8484589 , 0.71849316, 0.25478219],\n",
       "       [0.26169735, 0.71181814, 0.29730694, 0.05213373],\n",
       "       [0.06413137, 0.2130587 , 0.90989654, 0.87288178]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrade_dataset(X, missingness, rand, v):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        dataset to corrupt\n",
    "        % of data to eliminate[0,1]\n",
    "        rand random state\n",
    "        replace with = 'zero' or 'nan'\n",
    "      Outputs:\n",
    "        corrupted Dataset \n",
    "        binary mask\n",
    "    \"\"\"\n",
    "    X_1d = X.flatten()\n",
    "    n = len(X_1d)\n",
    "    mask_1d = np.ones(n)\n",
    "    print(mask_1d)\n",
    "    corrupt_ids = random.sample(range(n), int(missingness * n))\n",
    "    print(corrupt_ids)\n",
    "    for i in corrupt_ids:\n",
    "        X_1d[i] = v\n",
    "        mask_1d[i] = 0\n",
    "\n",
    "    cX = X_1d.reshape(X.shape)\n",
    "    mask = mask_1d.reshape(X.shape)\n",
    "\n",
    "    return cX, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[10, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.30496917,        nan, 0.71849316, 0.25478219],\n",
       "        [0.26169735, 0.71181814, 0.29730694, 0.05213373],\n",
       "        [0.06413137, 0.2130587 ,        nan, 0.87288178]]),\n",
       " array([[1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 0., 1.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrade_dataset(X_train, 0.2, 42, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30496917, 0.8484589 , 0.71849316, 0.25478219],\n",
       "       [0.26169735, 0.71181814, 0.29730694, 0.05213373],\n",
       "       [0.06413137, 0.2130587 , 0.90989654, 0.87288178]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_K_Fold = \"C:\\\\Users\\\\DELL\\\\Desktop\\\\Research\\\\Imputation_Surveys\\\\data_K_Fold\"\n",
    "file_name = 'abalone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader(save_folder, file_name, i, method, missingness):\n",
    "    '''Loader csv files \n",
    "    Args:\n",
    "    - save_folder: path to save directory\n",
    "    - file_name: name of UCI datasets (ex: abalone, heart, tic-tac-toe)\n",
    "    - i: index of fold_size\n",
    "    - method: original data or missing data \n",
    "    - missingness: missingness constant\n",
    "\n",
    "    Returns:\n",
    "    - X_train: matrix train data\n",
    "    - X_test:  matrix test data\n",
    "    '''\n",
    "    file_name_folder = os.path.join(save_folder, file_name)\n",
    "    if method == 'original_data' and missingness == None:\n",
    "        train_folder = os.path.join(file_name_folder, 'train/original_data')\n",
    "        check_exist_folder(train_folder)\n",
    "        test_folder = os.path.join(file_name_folder, 'test/original_data')\n",
    "        check_exist_folder(test_folder)\n",
    "        train_path = os.path.join(train_folder, 'train_{}.csv'.format(i))\n",
    "        test_path = os.path.join(test_folder, 'test_{}.csv'.format(i))\n",
    "    elif method == 'data_missing':\n",
    "        train_folder = os.path.join(file_name_folder, 'train/train_{}'.format(i))\n",
    "        test_folder = os.path.join(file_name_folder, 'test/test_{}'.format(i))\n",
    "        train_path = os.path.join(train_folder, 'train_{}_missing_{}.csv'.format(i, missingness))\n",
    "        test_path = os.path.join(test_folder, 'test_{}_missing_{}.csv'.format(i, missingness))\n",
    "    # Loading train and test csv\n",
    "    X_train = np.genfromtxt(train_path, delimiter=',')\n",
    "    X_test = np.genfromtxt(test_path, delimiter=',')\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "(D_miss_train, D_miss_test) = csv_reader(data_K_Fold, file_name, 1, method='data_missing', missingness=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    nan,  0.435 ,  0.17  , ...,  0.2705,     nan,  3.    ],\n",
       "       [ 0.69  ,  0.55  ,  0.18  , ...,  0.5   , 11.    ,  3.    ],\n",
       "       [    nan,     nan,     nan, ...,     nan, 10.    ,  3.    ],\n",
       "       ...,\n",
       "       [ 0.64  ,  0.5   ,  0.17  , ...,  0.354 ,  9.    ,  3.    ],\n",
       "       [ 0.62  ,  0.485 ,  0.155 , ...,  0.352 ,  9.    ,  1.    ],\n",
       "       [ 0.49  ,  0.39  ,  0.15  , ...,  0.17  , 21.    ,  3.    ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_miss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   nan,  0.435,  0.17 , ...,  0.17 , 21.   ,  3.   ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = D_miss_train.flatten()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.isnan(X[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 5,\n",
       " 7,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 24,\n",
       " 28,\n",
       " 36,\n",
       " 42,\n",
       " 43,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 81,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 91,\n",
       " 93,\n",
       " 94,\n",
       " 97,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 123,\n",
       " 142,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 218,\n",
       " 219,\n",
       " 222,\n",
       " 223,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 264,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 325,\n",
       " 327,\n",
       " 335,\n",
       " 338,\n",
       " 339,\n",
       " 349,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 391,\n",
       " 393,\n",
       " 394,\n",
       " 396,\n",
       " 399,\n",
       " 400,\n",
       " 403,\n",
       " 460,\n",
       " 462,\n",
       " 463,\n",
       " 465,\n",
       " 466,\n",
       " 477,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 581,\n",
       " 648,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 667,\n",
       " 668,\n",
       " 670,\n",
       " 686,\n",
       " 687,\n",
       " 690,\n",
       " 691,\n",
       " 714,\n",
       " 716,\n",
       " 718,\n",
       " 793,\n",
       " 795,\n",
       " 797,\n",
       " 798,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 819,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 900,\n",
       " 902,\n",
       " 905,\n",
       " 918,\n",
       " 919,\n",
       " 922,\n",
       " 940,\n",
       " 941,\n",
       " 990,\n",
       " 997,\n",
       " 1044,\n",
       " 1045,\n",
       " 1046,\n",
       " 1047,\n",
       " 1048,\n",
       " 1049,\n",
       " 1051,\n",
       " 1081,\n",
       " 1084,\n",
       " 1085,\n",
       " 1086,\n",
       " 1089,\n",
       " 1091,\n",
       " 1093,\n",
       " 1094,\n",
       " 1095,\n",
       " 1096,\n",
       " 1107,\n",
       " 1110,\n",
       " 1112,\n",
       " 1113,\n",
       " 1114,\n",
       " 1116,\n",
       " 1117,\n",
       " 1118,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1122,\n",
       " 1123,\n",
       " 1125,\n",
       " 1126,\n",
       " 1127,\n",
       " 1128,\n",
       " 1129,\n",
       " 1130,\n",
       " 1152,\n",
       " 1153,\n",
       " 1154,\n",
       " 1155,\n",
       " 1156,\n",
       " 1158,\n",
       " 1159,\n",
       " 1197,\n",
       " 1198,\n",
       " 1202,\n",
       " 1203,\n",
       " 1204,\n",
       " 1224,\n",
       " 1226,\n",
       " 1227,\n",
       " 1228,\n",
       " 1229,\n",
       " 1230,\n",
       " 1231,\n",
       " 1251,\n",
       " 1252,\n",
       " 1253,\n",
       " 1254,\n",
       " 1255,\n",
       " 1256,\n",
       " 1257,\n",
       " 1258,\n",
       " 1279,\n",
       " 1285,\n",
       " 1296,\n",
       " 1300,\n",
       " 1301,\n",
       " 1302,\n",
       " 1314,\n",
       " 1316,\n",
       " 1318,\n",
       " 1320,\n",
       " 1325,\n",
       " 1329,\n",
       " 1352,\n",
       " 1355,\n",
       " 1357,\n",
       " 1459,\n",
       " 1460,\n",
       " 1462,\n",
       " 1463,\n",
       " 1464,\n",
       " 1469,\n",
       " 1485,\n",
       " 1486,\n",
       " 1487,\n",
       " 1488,\n",
       " 1490,\n",
       " 1491,\n",
       " 1492,\n",
       " 1494,\n",
       " 1495,\n",
       " 1497,\n",
       " 1498,\n",
       " 1543,\n",
       " 1548,\n",
       " 1549,\n",
       " 1550,\n",
       " 1554,\n",
       " 1555,\n",
       " 1557,\n",
       " 1558,\n",
       " 1559,\n",
       " 1560,\n",
       " 1561,\n",
       " 1562,\n",
       " 1563,\n",
       " 1564,\n",
       " 1585,\n",
       " 1586,\n",
       " 1587,\n",
       " 1588,\n",
       " 1590,\n",
       " 1591,\n",
       " 1618,\n",
       " 1631,\n",
       " 1632,\n",
       " 1635,\n",
       " 1636,\n",
       " 1665,\n",
       " 1670,\n",
       " 1685,\n",
       " 1692,\n",
       " 1693,\n",
       " 1694,\n",
       " 1695,\n",
       " 1696,\n",
       " 1697,\n",
       " 1698,\n",
       " 1699,\n",
       " 1710,\n",
       " 1712,\n",
       " 1714,\n",
       " 1728,\n",
       " 1731,\n",
       " 1733,\n",
       " 1734,\n",
       " 1828,\n",
       " 1829,\n",
       " 1834,\n",
       " 1922,\n",
       " 1935,\n",
       " 1936,\n",
       " 1937,\n",
       " 1938,\n",
       " 1942,\n",
       " 1971,\n",
       " 1972,\n",
       " 1973,\n",
       " 1974,\n",
       " 1975,\n",
       " 1976,\n",
       " 1977,\n",
       " 1978,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2022,\n",
       " 2023,\n",
       " 2120,\n",
       " 2121,\n",
       " 2128,\n",
       " 2151,\n",
       " 2152,\n",
       " 2153,\n",
       " 2154,\n",
       " 2155,\n",
       " 2156,\n",
       " 2157,\n",
       " 2158,\n",
       " 2160,\n",
       " 2162,\n",
       " 2180,\n",
       " 2184,\n",
       " 2250,\n",
       " 2253,\n",
       " 2254,\n",
       " 2256,\n",
       " 2257,\n",
       " 2259,\n",
       " 2260,\n",
       " 2261,\n",
       " 2262,\n",
       " 2263,\n",
       " 2264,\n",
       " 2265,\n",
       " 2266,\n",
       " 2268,\n",
       " 2269,\n",
       " 2270,\n",
       " 2271,\n",
       " 2272,\n",
       " 2274,\n",
       " 2275,\n",
       " 2277,\n",
       " 2278,\n",
       " 2279,\n",
       " 2280,\n",
       " 2281,\n",
       " 2282,\n",
       " 2283,\n",
       " 2284,\n",
       " 2333,\n",
       " 2336,\n",
       " 2338,\n",
       " 2376,\n",
       " 2377,\n",
       " 2381,\n",
       " 2382,\n",
       " 2412,\n",
       " 2417,\n",
       " 2466,\n",
       " 2467,\n",
       " 2468,\n",
       " 2469,\n",
       " 2470,\n",
       " 2471,\n",
       " 2472,\n",
       " 2473,\n",
       " 2475,\n",
       " 2478,\n",
       " 2481,\n",
       " 2482,\n",
       " 2502,\n",
       " 2505,\n",
       " 2507,\n",
       " 2508,\n",
       " 2520,\n",
       " 2521,\n",
       " 2522,\n",
       " 2523,\n",
       " 2524,\n",
       " 2525,\n",
       " 2526,\n",
       " 2527,\n",
       " 2538,\n",
       " 2539,\n",
       " 2543,\n",
       " 2545,\n",
       " 2568,\n",
       " 2570,\n",
       " 2571,\n",
       " 2572,\n",
       " 2601,\n",
       " 2602,\n",
       " 2603,\n",
       " 2606,\n",
       " 2607,\n",
       " 2628,\n",
       " 2629,\n",
       " 2632,\n",
       " 2633,\n",
       " 2634,\n",
       " 2635,\n",
       " 2696,\n",
       " 2700,\n",
       " 2701,\n",
       " 2702,\n",
       " 2703,\n",
       " 2704,\n",
       " 2705,\n",
       " 2706,\n",
       " 2707,\n",
       " 2709,\n",
       " 2710,\n",
       " 2711,\n",
       " 2712,\n",
       " 2713,\n",
       " 2714,\n",
       " 2715,\n",
       " 2716,\n",
       " 2727,\n",
       " 2728,\n",
       " 2729,\n",
       " 2730,\n",
       " 2732,\n",
       " 2733,\n",
       " 2734,\n",
       " 2736,\n",
       " 2737,\n",
       " 2739,\n",
       " 2740,\n",
       " 2741,\n",
       " 2742,\n",
       " 2743,\n",
       " 2763,\n",
       " 2765,\n",
       " 2766,\n",
       " 2768,\n",
       " 2769,\n",
       " 2802,\n",
       " 2806,\n",
       " 2808,\n",
       " 2809,\n",
       " 2810,\n",
       " 2812,\n",
       " 2813,\n",
       " 2814,\n",
       " 2815,\n",
       " 2848,\n",
       " 2850,\n",
       " 2936,\n",
       " 2937,\n",
       " 2938,\n",
       " 2939,\n",
       " 2940,\n",
       " 2970,\n",
       " 2971,\n",
       " 2972,\n",
       " 2975,\n",
       " 2988,\n",
       " 2989,\n",
       " 2990,\n",
       " 2991,\n",
       " 2992,\n",
       " 2993,\n",
       " 2994,\n",
       " 2995,\n",
       " 3087,\n",
       " 3088,\n",
       " 3089,\n",
       " 3091,\n",
       " 3092,\n",
       " 3093,\n",
       " 3101,\n",
       " 3102,\n",
       " 3135,\n",
       " 3138,\n",
       " 3146,\n",
       " 3168,\n",
       " 3169,\n",
       " 3170,\n",
       " 3171,\n",
       " 3172,\n",
       " 3173,\n",
       " 3175,\n",
       " 3217,\n",
       " 3218,\n",
       " 3234,\n",
       " 3235,\n",
       " 3238,\n",
       " 3264,\n",
       " 3285,\n",
       " 3286,\n",
       " 3287,\n",
       " 3288,\n",
       " 3290,\n",
       " 3291,\n",
       " 3292,\n",
       " 3295,\n",
       " 3297,\n",
       " 3298,\n",
       " 3299,\n",
       " 3301,\n",
       " 3304,\n",
       " 3305,\n",
       " 3306,\n",
       " 3309,\n",
       " 3310,\n",
       " 3312,\n",
       " 3314,\n",
       " 3315,\n",
       " 3316,\n",
       " 3319,\n",
       " 3384,\n",
       " 3391,\n",
       " 3429,\n",
       " 3431,\n",
       " 3434,\n",
       " 3435,\n",
       " 3449,\n",
       " 3450,\n",
       " 3452,\n",
       " 3453,\n",
       " 3454,\n",
       " 3459,\n",
       " 3461,\n",
       " 3519,\n",
       " 3521,\n",
       " 3524,\n",
       " 3638,\n",
       " 3639,\n",
       " 3640,\n",
       " 3641,\n",
       " 3642,\n",
       " 3643,\n",
       " 3654,\n",
       " 3655,\n",
       " 3656,\n",
       " 3657,\n",
       " 3658,\n",
       " 3660,\n",
       " 3661,\n",
       " 3708,\n",
       " 3709,\n",
       " 3712,\n",
       " 3713,\n",
       " 3727,\n",
       " 3728,\n",
       " 3729,\n",
       " 3733,\n",
       " 3772,\n",
       " 3773,\n",
       " 3774,\n",
       " 3777,\n",
       " 3807,\n",
       " 3808,\n",
       " 3809,\n",
       " 3810,\n",
       " 3813,\n",
       " 3814,\n",
       " 3835,\n",
       " 3895,\n",
       " 3906,\n",
       " 3908,\n",
       " 3910,\n",
       " 3913,\n",
       " 3924,\n",
       " 3925,\n",
       " 3926,\n",
       " 3927,\n",
       " 3929,\n",
       " 3931,\n",
       " 3970,\n",
       " 3971,\n",
       " 3972,\n",
       " 3973,\n",
       " 3974,\n",
       " 3976,\n",
       " 3978,\n",
       " 3979,\n",
       " 3980,\n",
       " 3981,\n",
       " 3982,\n",
       " 3983,\n",
       " 3984,\n",
       " 3985,\n",
       " 4024,\n",
       " 4026,\n",
       " 4028,\n",
       " 4032,\n",
       " 4033,\n",
       " 4034,\n",
       " 4036,\n",
       " 4038,\n",
       " 4123,\n",
       " 4158,\n",
       " 4160,\n",
       " 4163,\n",
       " 4164,\n",
       " 4165,\n",
       " 4189,\n",
       " 4191,\n",
       " 4259,\n",
       " 4263,\n",
       " 4295,\n",
       " 4296,\n",
       " 4297,\n",
       " 4299,\n",
       " 4300,\n",
       " 4303,\n",
       " 4307,\n",
       " 4329,\n",
       " 4330,\n",
       " 4331,\n",
       " 4332,\n",
       " 4334,\n",
       " 4335,\n",
       " 4336,\n",
       " 4365,\n",
       " 4366,\n",
       " 4367,\n",
       " 4368,\n",
       " 4369,\n",
       " 4370,\n",
       " 4371,\n",
       " 4372,\n",
       " 4438,\n",
       " 4440,\n",
       " 4441,\n",
       " 4442,\n",
       " 4443,\n",
       " 4444,\n",
       " 4482,\n",
       " 4483,\n",
       " 4484,\n",
       " 4485,\n",
       " 4486,\n",
       " 4487,\n",
       " 4488,\n",
       " 4489,\n",
       " 4583,\n",
       " 4584,\n",
       " 4585,\n",
       " 4588,\n",
       " 4618,\n",
       " 4619,\n",
       " 4621,\n",
       " 4622,\n",
       " 4624,\n",
       " 4645,\n",
       " 4649,\n",
       " 4650,\n",
       " 4651,\n",
       " 4662,\n",
       " 4663,\n",
       " 4698,\n",
       " 4699,\n",
       " 4700,\n",
       " 4702,\n",
       " 4703,\n",
       " 4704,\n",
       " 4705,\n",
       " 4749,\n",
       " 4750,\n",
       " 4806,\n",
       " 4807,\n",
       " 4808,\n",
       " 4809,\n",
       " 4810,\n",
       " 4811,\n",
       " 4812,\n",
       " 4813,\n",
       " 4860,\n",
       " 4861,\n",
       " 4863,\n",
       " 4864,\n",
       " 4865,\n",
       " 4866,\n",
       " 4867,\n",
       " 4923,\n",
       " 4924,\n",
       " 4925,\n",
       " 4930,\n",
       " 4944,\n",
       " 4947,\n",
       " 4987,\n",
       " 4988,\n",
       " 4989,\n",
       " 4990,\n",
       " 4992,\n",
       " 4993,\n",
       " 5008,\n",
       " 5011,\n",
       " 5018,\n",
       " 5031,\n",
       " 5033,\n",
       " 5038,\n",
       " 5158,\n",
       " 5159,\n",
       " 5161,\n",
       " 5163,\n",
       " 5164,\n",
       " 5221,\n",
       " 5224,\n",
       " 5226,\n",
       " 5248,\n",
       " 5249,\n",
       " 5250,\n",
       " 5251,\n",
       " 5252,\n",
       " 5253,\n",
       " 5254,\n",
       " 5256,\n",
       " 5257,\n",
       " 5258,\n",
       " 5261,\n",
       " 5262,\n",
       " 5271,\n",
       " 5272,\n",
       " 5321,\n",
       " 5322,\n",
       " 5325,\n",
       " 5326,\n",
       " 5328,\n",
       " 5332,\n",
       " 5337,\n",
       " 5338,\n",
       " 5339,\n",
       " 5340,\n",
       " 5341,\n",
       " 5342,\n",
       " 5343,\n",
       " 5344,\n",
       " 5409,\n",
       " 5410,\n",
       " 5411,\n",
       " 5412,\n",
       " 5413,\n",
       " 5414,\n",
       " 5415,\n",
       " 5427,\n",
       " 5428,\n",
       " 5429,\n",
       " 5430,\n",
       " 5431,\n",
       " 5432,\n",
       " 5433,\n",
       " 5434,\n",
       " 5494,\n",
       " 5495,\n",
       " 5496,\n",
       " 5497,\n",
       " 5508,\n",
       " 5512,\n",
       " 5522,\n",
       " 5523,\n",
       " 5524,\n",
       " 5572,\n",
       " 5576,\n",
       " 5577,\n",
       " 5583,\n",
       " 5584,\n",
       " 5614,\n",
       " 5661,\n",
       " 5662,\n",
       " 5665,\n",
       " 5666,\n",
       " 5668,\n",
       " 5681,\n",
       " 5682,\n",
       " 5683,\n",
       " 5684,\n",
       " 5685,\n",
       " 5734,\n",
       " 5735,\n",
       " 5736,\n",
       " 5738,\n",
       " 5739,\n",
       " 5751,\n",
       " 5752,\n",
       " 5753,\n",
       " 5754,\n",
       " 5755,\n",
       " 5758,\n",
       " 5791,\n",
       " 5792,\n",
       " 5794,\n",
       " 5823,\n",
       " 5824,\n",
       " 5825,\n",
       " 5826,\n",
       " 5827,\n",
       " 5828,\n",
       " 5829,\n",
       " 5830,\n",
       " 5841,\n",
       " 5842,\n",
       " 5843,\n",
       " 5844,\n",
       " 5845,\n",
       " 5846,\n",
       " 5847,\n",
       " 5848,\n",
       " 5967,\n",
       " 5968,\n",
       " 5969,\n",
       " 5971,\n",
       " 5974,\n",
       " 6057,\n",
       " 6058,\n",
       " 6059,\n",
       " 6060,\n",
       " 6062,\n",
       " 6063,\n",
       " 6064,\n",
       " 6066,\n",
       " 6067,\n",
       " 6068,\n",
       " 6069,\n",
       " 6070,\n",
       " 6071,\n",
       " 6072,\n",
       " 6073,\n",
       " 6111,\n",
       " 6112,\n",
       " 6114,\n",
       " 6115,\n",
       " 6117,\n",
       " 6118,\n",
       " 6210,\n",
       " 6211,\n",
       " 6213,\n",
       " 6214,\n",
       " 6216,\n",
       " 6217,\n",
       " 6247,\n",
       " 6249,\n",
       " 6256,\n",
       " 6257,\n",
       " 6258,\n",
       " 6261,\n",
       " 6262,\n",
       " 6273,\n",
       " 6274,\n",
       " 6275,\n",
       " 6277,\n",
       " 6278,\n",
       " 6280,\n",
       " 6327,\n",
       " 6328,\n",
       " 6329,\n",
       " 6330,\n",
       " 6331,\n",
       " 6332,\n",
       " 6333,\n",
       " 6355,\n",
       " 6372,\n",
       " 6373,\n",
       " 6374,\n",
       " 6375,\n",
       " 6376,\n",
       " 6377,\n",
       " 6378,\n",
       " 6379,\n",
       " 6383,\n",
       " 6387,\n",
       " 6388,\n",
       " 6417,\n",
       " 6419,\n",
       " 6420,\n",
       " 6421,\n",
       " 6422,\n",
       " 6423,\n",
       " 6424,\n",
       " 6427,\n",
       " 6430,\n",
       " 6431,\n",
       " 6432,\n",
       " 6436,\n",
       " 6438,\n",
       " 6441,\n",
       " 6489,\n",
       " 6507,\n",
       " 6508,\n",
       " 6509,\n",
       " 6510,\n",
       " 6512,\n",
       " 6513,\n",
       " 6514,\n",
       " 6518,\n",
       " 6519,\n",
       " 6520,\n",
       " 6521,\n",
       " 6523,\n",
       " 6562,\n",
       " 6579,\n",
       " 6580,\n",
       " 6581,\n",
       " 6582,\n",
       " 6583,\n",
       " 6597,\n",
       " 6598,\n",
       " 6599,\n",
       " 6600,\n",
       " 6601,\n",
       " 6602,\n",
       " 6603,\n",
       " 6604,\n",
       " 6607,\n",
       " 6608,\n",
       " 6609,\n",
       " 6611,\n",
       " 6612,\n",
       " 6613,\n",
       " 6618,\n",
       " 6621,\n",
       " 6642,\n",
       " 6644,\n",
       " 6687,\n",
       " 6707,\n",
       " 6708,\n",
       " 6709,\n",
       " 6712,\n",
       " 6724,\n",
       " 6727,\n",
       " 6759,\n",
       " 6760,\n",
       " 6761,\n",
       " 6766,\n",
       " 6770,\n",
       " 6771,\n",
       " 6772,\n",
       " 6773,\n",
       " 6774,\n",
       " 6813,\n",
       " 6818,\n",
       " 6820,\n",
       " 6843,\n",
       " 6975,\n",
       " 7065,\n",
       " 7066,\n",
       " 7067,\n",
       " 7068,\n",
       " 7070,\n",
       " 7071,\n",
       " 7072,\n",
       " 7075,\n",
       " 7077,\n",
       " 7080,\n",
       " 7086,\n",
       " 7110,\n",
       " 7112,\n",
       " 7113,\n",
       " 7114,\n",
       " 7115,\n",
       " 7116,\n",
       " 7117,\n",
       " 7151,\n",
       " 7155,\n",
       " 7158,\n",
       " 7161,\n",
       " 7164,\n",
       " 7169,\n",
       " 7170,\n",
       " 7191,\n",
       " 7192,\n",
       " 7193,\n",
       " 7194,\n",
       " 7195,\n",
       " 7196,\n",
       " 7197,\n",
       " 7198,\n",
       " 7200,\n",
       " 7204,\n",
       " 7205,\n",
       " 7206,\n",
       " 7207,\n",
       " 7263,\n",
       " 7265,\n",
       " 7267,\n",
       " 7269,\n",
       " ...]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_id = [i for i, element in enumerate(X) if math.isnan(element)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_generation(missing_matrix):\n",
    "    data_1d = missing_matrix.flatten()\n",
    "    n_data = len(data_1d)\n",
    "    mask_1d = np.ones(n_data)\n",
    "    \n",
    "    nan_id = [i for i, element in enumerate(data_1d) if math.isnan(element)]\n",
    "    for i in nan_id:\n",
    "        mask_1d[i] = 0\n",
    "    \n",
    "    mask = mask_1d.reshape(missing_matrix.shape)\n",
    "    \n",
    "    return missing_matrix, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
